Kafka Notes
============
- Apache Kafka is an open-source, distributed event streaming platform that can handle high-volume data feed in real-time
- Allows you to publish, subscribe, store, and process streams of records in real-time, 
- used for building data pipelines, analytics, and event-driven applications.

Core Concepts
Topics: Categories for data streams (e.g., "user_clicks", "orders").
Producers: Applications that send (publish) data to topics.
Consumers: Applications that subscribe to and read data from topics.
Brokers: Servers that store and manage the data partitions.
Partitions: Topics are divided into partitions for parallel processing, increasing throughput and scalability. 

Kafka Topics
- Topics: a particular stream of data
- Like a table in a database (without all the constraints)
- You can have as many topics as you want
- A topic is identified by its name
- Any kind of message format
- The sequence of messages is called a data stream
- You cannot query topics, instead, use Kafka Producers to send data and Kafka Consumers to read the data

Partitions and offsets
- Topics are split in partitions (example: 100 partitions)
    - Messages within each partition are ordered
    - Each message within a partition gets an incremental id, called offset
- Kafka topics are immutable: once data is written to a partition, it cannot be changed

Topics, partitions and offsets 
- Once the data is written to a partition, it cannot be changed (immutability)
- Data is kept only for a limited time (default is one week - configurable)
- Offset only have a meaning for a specific partition.
    - E.g. offset 3 in partition 0 doesn't represent the same data as offset 3 in partition 1
    - Offsets are not re-used even if previous messages have been deleted
- Order is guaranteed only within a partition (not across partitions)
- Data is assigned randomly to a partition unless a key is provided
- You can have as many partitions per topic as you want

Producers
- Producers write data to topics (which are made of partitions)
- Producers know to which partition to write to (and which Kafka broker has it)
- In case of Kafka broker failures, Producers will automatically recover

Kafka Message Serializer
- Kafka only accepts bytes as an input from producers and sends bytes out as an output to consumers
- Message Serialization means transforming objects / data into bytes
- They are used on the value and the key
- Common Serializers
    - String (incl. JSON)
    - Int, Float
    - Avro
    - Protobuf

Key Object  ->      Key Serializer      ->  Key-binary
123                 IntegerSerializer       0101
Value Object  ->    Value Serializer    ->  Value-binary
"hello"             StringSerializer       0101

Kafka Message Key Hashing
- A Kafka partitioner is a code logic that takes a record and determines to which partition to send it into
    Record -> Producer partitioner logic -> Partition1

Consumers
- Consumers read data from a topic (identified by name) - pull model
- Consumers automatically know which broker to read from
- In case of broker failures, consumers know how to recover
- Data is read in order from low to high offset within each partition

Consumer Deserializer
- Deserialize indicates how to transform bytes into objects / data
- They are used on the value and the key of the message
- Common Deserializers
    - String (incl. JSON)
    - Int, Float
    - Avro
    - Protobuf
- The serialization / deserialization type must not change during a topic lifecycle (create a new topic instead)

Consumer Groups
- All the consumers in an application read data as a consumer groups
- Each consumer within a group reads from exclusive partitions
      Partition0     Partition1     Partition2      Partition3        (One topic with four partitions)
            |       /                  |                |
            Consumer1               Consumer2       Consumer3         (Three docker container instances of same app)
                  consumer-group-application                          (One application )
- If you have more consumers than partitions, some consumers will be inactive
- In Apache Kafka it is acceptable to have multiple consumer groups on the same topic
        Topic1
      Partition0    Partition1     Partition2      Partition3
        |           |                   |                |
        ||//       \|//               \\|/            \\\| 
      Consumer1   Consumer2             Consumer1       Consumer2
      consumer-group-application1       consumer-group-application2
- By default, each application forms a single consumer-group

Consumer Offsets
- Kafka stores the offsets at which a consumer group has been reading
- The offsets committed are in Kafka topic named __consumer_offsets
- When a consumer in a group has processed data received from Kafka, it should be periodically committing the offsets
 (the Kafka broker will write to __consumer_offsets, not the group itself)
- If a consumer dies, it will be able to read back from where it left off thanks to the committed consumer offset.

Delivery semantics for consumers
- By default, Java Consumers will automatically commit offsets (at least once)
- There are 3 delivery semantics if you choose to commit manually
- At least once (usually preferred)
    - Offsets are committed after the message is processed
    - If the processing goes wrong, the message will be read again
    - This can result in duplicate processing of messages. Make sure your processing is idempotent (i.e. processing again the messages won't impact your systems)
- At most once
    - Offsets are committed as soon as messages are received
    - If the processing goes wrong, some messages will be lost (they won't be read again)
- Exactly once
    - For Kafka => Kafka workflows: use the Transactional API (easy with Kafka Streams API)
    - For Kafka => External System workflows: use an idempotent consumer

Kafka Brokers
- A Kafka cluster is composed of multiple brokers (servers)
- Each broker is identified with its ID (integer)
- Each broker contains certain topic partitions
- After connecting to any broker (called a bootstrap broker), you will be connected to the entire cluster 
    (Kafka clients have smart mechanics for that)
- A good number to get started is 3 brokers, but some big clusters have over 100
- Example of Topic-A with 3 partitions and Topic-B with 2 partitions
    Note: data is distributed, and Broker 103 doesn't have any Topic B data
    Broker101           Broker102           Broker103

    TopicA              TopicA              TopicA
    Partition0          Partition1          Partition2

    TopicB              TopicB
    Partition1          Partition0

Kafka Broker Discovery
- Every Kafka broker is also called a "bootstrap server"
- That means that you only need to connect to one broker, and the Kafka clients will know how to be connected to the
  entire cluster (smart clients)
- Each broker knows about all brokers, topics and partitions (metadata)

Topic replication factor
- Topics should have a replication factor > 1 (usually between 2 and 3)
- This way if a broker is down, another broker can serve the data
- Example: Topic-A with 2 partitions and replication factor of 2
    Broker101           Broker102           Broker103

    TopicA              TopicA   ---Repl--- TopicA
    Partition0          Partition1          Partition1
          L_  
            Repl______  TopicA
                        Partition0
 
Concept of Leader for a Partition
- At any time only ONE broker can be a leader for a given partition
- Producers can only send data to the broker that is leader of a partition
- The other brokers will replicate the data
- Therefore, each partition has one leader and multiple ISR (in-sync replica)

Default producer & consumer behavior with leaders
- Kafka Producers can only write to the leader broker for a partition
- Kafka Consumers by default will read from the leader broker for a partition

Kafka Consumers Replica Fetching (Kafka v2.4+)
- Since Kafka 2.4, it is possible to configure consumers to read from the closest replica
- This may help improve latency, and also decrease network costs if using the cloud

Producer Acknowledgements (acks)
Producers can choose to receive acknowledgment of data writes:
- acks=0: Producer won't wait for acknowledgment (possible data loss)
- acks=1: Producer will wait for leader acknowledgment (limited data loss)
- acks=all: Leader + replicas acknowledgment (no data loss)

Kafka Topic Durability
- For a topic replication factor of 3, topic data durability can withstand 2 brokers loss.
- As a rule, for a replication factor of N, you can permanently lose up to N-1 brokers and still recover your data.

Zookeeper
- Zookeeper manages brokers (keeps a list of them)
- Zookeeper helps in performing leader election for partitions
- Zookeeper sends notifications to Kafka in case of changes (e.g. new topic, broker dies, broker comes up, delete topics, etc....)
- Katka 2.x can't work without Zookeeper
- Kafka 3.x can work without Zookeeper (KIP-500) - using Kafka Raft instead
- Kafka 4.x will not have Zookeeper
- Zookeeper by design operates with an odd number of servers (1, 3, 5, 7)
- Zookeeper has a leader (writes) the rest of the servers are followers (reads)
- (Zookeeper does NOT store consumer offsets with Kafka > v0.10)

Should you use Zookeeper?
- With Kafka Brokers?
    - Yes, until Kafka 4.0 is out while waiting for Kafka without Zookeeper to be production-ready
- With Kafka Clients?
    - Over time, the Kafka clients and CLI have been migrated to leverage the brokers as a connection endpoint instead of Zookeeper
    - Since Kafka 0.10, consumers store offset in Kafka and Zookeeper and must not connect to Zookeeper as it is deprecated
    - Since Kafka 2.2, the kafka-topics.sh CLI command references Kafka brokers and not Zookeeper for topic management (creation, deletion, etc...) and the Zookeeper CLI argument is deprecated.
    - All the APIs and commands that were previously levaraging Zookeeper are migrated to use Kafka instead, so that when clusters are migrated to be without Zookeeper, the change is invisible to clients. 
    - Zookeeper is also less secure than Kafka, and therefore Zookeeper ports should only be opened to allow traffic from Kafka brokers, and not Kafka clients
    - Therefore, to be a great modern-day Kafka developer, never ever use Zookeeper as a configuration in your Kafka clients, and other programs that connect to Kafka.

About Kafka KRaft
- In 2020, the Apache Kafka project started to work to remove the Zookeeper dependency from it (KIP-500)
- Zookeeper shows scaling issues when Kafka clusters have > 100,000 partitions
- By removing Zookeeper, Apache Kafka can
    - Scale to millions of partitions, and becomes easier to maintain and set-up
    - Improve stability, makes it easier to monitor, support and administer
    - Single security model for the whole system
    - Single process to start with Kafka
    - Faster controller shutdown and recovery time
- Kafka 3.X now implements the Raft protocol (KRaft) in order to replace Zookeeper
    - Production ready since Kafka 3.3.1 (KIP-833)
    - Kafka 4.0 will be released only with KRaft (no Zookeeper)

Wikimedia
---------
Git:    https://github.com/conduktor/kafka-beginners-course.git
Recent change stream:   https://stream.wikimedia.org/v2/stream/recentchange
Demo https://codepen.io/Krinkle/pen/BwEKgW?editors=1010
Wikimedia Event Stream Demo: https://esjewett.github.io/wm-eventsource-demo/

https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster/
https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines


Q: Can two consumer read messages from same partition?
A: Within same consumer group - NO
    Across different consumer group - YES

    topic1     CG1  
    ------     ---- 
    p1 ------- con1 
        |__X__ con2 

    topic1     CG1      CG2
    ------     ----     -----
    p1 ------- con1 --- con3
    p2 ------- con2 --- con4


Q: if producer send 3 messages to a Kafka topic having 3 partitions. How it will get processed?
A:
1. If You Provide No Key (Default)
  In modern Kafka versions (2.4+), the default behavior is Sticky Partitioning. 
  How it works: To optimize performance, Kafka groups messages into "batches" and sends the entire batch to a single partition.
  Result: It is highly likely that all 3 small messages will be sent to the same partition in one batch to reduce network overhead.
  Older Versions: Prior to version 2.4, Kafka used a strict round-robin strategy for null keys, which would have resulted in exactly one message per partition
2. If You Use a Message Key
  If you provide a key with each message, Kafka uses a hashing algorithm (Murmur2) to determine the partition. 
  Same Key: If all 3 messages have the same key, they will all go to the same partition to guarantee ordering.
  Different Keys: If they have different keys, they might be distributed across different partitions. 
   However, there is no guarantee they will land in separate partitions (e.g., two keys could hash to the same partition)
3. If You Manually Specify Partitions
  You can explicitly tell the producer which partition to use for each message (e.g., Message 1 to Partition 0, Message 2 to Partition 1, etc.). 
  In this case, you can guarantee that each partition gets exactly one message
    Summary Table
    Scenario 	                Likely Distribution
    No Key (Modern Kafka)	    All 3 in the same partition (due to batching/sticky partitioning).
    No Key (Old Kafka <2.4)	    1 message per partition (round-robin).
    Same Key for all	        All 3 in the same partition (guarantees order).
    Manual Assignment	        1 message per partition (if programmed that way).


Q: If we have three threads in a single container, will we call them three consumers ? will they read from three different partitions ?
A: Depends on how you have implemented your application
1. Are they called "three consumers"?
  Yes, if each thread instantiates its own KafkaConsumer object. 
  In Kafka terms, each independent KafkaConsumer instance that joins a consumer group is considered a separate consumer instance.
  No, if there is only one KafkaConsumer instance that polls data and then hands it off to three worker threads for processing. In this case, you have one consumer and three workers.
2. Will they read from three different partitions?
  This depends on your threading model and the number of partitions available:
  Thread-per-Consumer Model: If each of your 3 threads runs its own KafkaConsumer instance and they are all in the same Consumer Group:
    - 3 Partitions: Kafka will assign exactly one partition to each thread.
    - More than 3 Partitions: Some threads will be assigned multiple partitions (e.g., one thread might get two, another gets one).
    - Fewer than 3 Partitions: Some threads will remain idle because Kafka never assigns more than one consumer in the same group to a single partition.
  Single-Consumer, Multi-Worker Model: If you have one consumer instance and 3 worker threads:
    - The single consumer will read from all 3 partitions itself and then distribute those messages to your threads.
    - Caution: This model makes offset management much more complex because you must ensure you don't commit an offset for a message until all previous messages from that partition have been processed by your workers.
    Summary Table
    Model 	        Definition	                                            Partition Assignment
    3 Consumers	    3 threads, each with its own KafkaConsumer instance.	Each thread gets 1 partition (if 3 partitions exist).
    1 Consumer	    1 thread with a KafkaConsumer, 3 worker threads.	    1 consumer reads all 3 partitions; workers just process data.
- For most standard applications, the thread-per-consumer model (e.g., using Spring Kafka's concurrency setting) is preferred because it handles partition rebalancing and offset management automatically for you


Q: If we have three instance of containers of same application, will that called three consumers ?
A: Yes, if you run three container instances of the same application and they share the same group.id, they are collectively called three consumer instances within a single Consumer Group.
1. Partition Assignment
    If your topic has 3 partitions and you have 3 container instances:
    One-to-One Mapping: Kafka's group coordinator will assign exactly one partition to each container.
    Parallel Processing: Each container will read and process messages from its assigned partition independently and in parallel with the others. 
2. Scalability and Limits
    The number of active consumers in a group is limited by the number of partitions:
    More Containers than Partitions: If you scale to 4 containers for 3 partitions, the 4th container will remain idle. It will not receive any data because a single partition can only be assigned to one consumer in a group at a time.
    Fewer Containers than Partitions: If you have 2 containers for 3 partitions, one container will be assigned two partitions, and the other will be assigned one.
3. Fault Tolerance
    If one container crashes:
    Automatic Rebalancing: Kafka detects the failure and triggers a rebalance.
    Takeover: The partition that was being handled by the failed container will be reassigned to one of the remaining two healthy containers so that processing continues.
Key Configurations
group.id: Must be identical across all three containers to ensure they work together as one logical unit.
group.instance.id: In modern cloud/container environments (like Kubernetes), setting a static group.instance.id can prevent unnecessary rebalances during container restarts
